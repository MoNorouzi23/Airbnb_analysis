{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0846bc-c666-4f1c-80bd-787713e88a19",
   "metadata": {},
   "source": [
    "# Airbnb Analysis: *Leveraging Machine Learning to Predict Listing Prices*\n",
    "\n",
    "by: Karan Khubdikar, Mo Norouzi, Nicole Bidwell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e26325-ad3a-4b08-b89e-33585c767562",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(current_dir, '..')))\n",
    "import pandas as pd \n",
    "from myst_nb import glue\n",
    "import joblib\n",
    "from src import config \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef54799e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "0.61"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "final_r2"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "58.77"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "rfecv_mae"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "0.686"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "lgbm_tuned_train"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "0.61"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "lgbm_tuned_test"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load files \n",
    "df = pd.read_csv(config.RAW_DATA)\n",
    "files = [config.CV_DUMMY_PATH, config.CV_LINEAR_PATH, config.CV_RF_PATH, config.CV_XGB_PATH, config.CV_LGBM_PATH]\n",
    "cv_results = [joblib.load(file) for file in files]\n",
    "cv_results_ensemble = pd.concat({k: v for d in cv_results for k, v in d.items()}, axis=1).drop(index=[\"fit_time\", \"score_time\"])\n",
    "tuned_files = [config.CV_RF_TUNED_PATH, config.CV_XGB_TUNED_PATH, config.CV_LGBM_TUNED_PATH, config.CV_RFECV_PATH]\n",
    "tuned_results_dict = [joblib.load(file) for file in tuned_files]\n",
    "tuned_results = pd.concat({k: v for d in tuned_results_dict for k, v in d.items()}, axis=1).drop(index=[\"fit_time\", \"score_time\"])\n",
    "cv_results_all = pd.concat([cv_results_ensemble, tuned_results], axis=1)\n",
    "feat_imp = pd.read_csv(config.FEAT_IMP_PATH).style.hide(axis=\"index\")\n",
    "mae_comparison = pd.read_csv(config.MAE_PATH)\n",
    "mae_comparison_style = mae_comparison.style.hide(axis=\"index\")\n",
    "mae_comparison['MAE'] = mae_comparison['MAE'].round(2)\n",
    "lgbm_tuned_test = tuned_results_dict[2][\"LGBM_Tuned\"][\"mean\"][\"test_score\"]\n",
    "lgbm_tuned_train = tuned_results_dict[2][\"LGBM_Tuned\"][\"mean\"][\"train_score\"]\n",
    "rfecv_mae = mae_comparison.loc[mae_comparison['Model'] == 'RFECV', 'MAE'].values[0]\n",
    "final_r2 = np.load(config.FINAL_R2_PATH)\n",
    "\n",
    "glue(\"final_r2\", np.round(final_r2, 2), display=False)\n",
    "glue(\"rfecv_mae\", rfecv_mae, display=False)\n",
    "glue(\"lgbm_tuned_train\", lgbm_tuned_train, display=False)\n",
    "glue(\"lgbm_tuned_test\", lgbm_tuned_test, display=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79545007",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this project, our group seeks to use machine learning algorithms to predict Airbnb listing prices using various property details like geographical location, room type, and review activity. We implement rigorous methods to analyze the data and build machine learning models, including exploratory data analysis, feature engineering, cross-validation, hyperparameter optimization, and feature selection. We explore several models including Ridge, Random Forest Regression, XGBoost, and LGBM Regressor, and incorporate Recursive Feature Elimination with Cross-validation (RFECV). The highest performing model was the RFECV model which combined L1 regularization and the LGBM Regressor. It obtained a $R^2$ test score of {glue:text}`final_r2` and a mean absolute error of {glue:text}`rfecv_mae`. Furthermore, we explored the SHAP values which provide valuable insights into feature importance and model interpretability, helping us better understand how individual features, such as location and room type, contribute to the predicted listing prices. While the best-performing RFECV reflects a reasonable level of performance, limitations and potential future improvements are outlined in the final discussion section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087b18b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "With over 8 million active listings across more than 100,000 cities and towns, Airbnb boasts an extensive network of accommodations, offering travelers a wide range of unique stays (Airbnb, 2024). As the popularity of short-term rentals remains high, understanding factors that influence listing prices becomes crucial for guests, hosts, and Airbnb. This analysis employs machine learning algorithms to predict Airbnb listing prices using property details like geographical location, room type, and review activity. By applying rigorous data analysis methods, we aim to uncover insights that not only enhance pricing strategies but also contribute to the broader understanding of market dynamics in the short-term rental sector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dcb2ec-0434-41ae-bf6f-e490564dd4ee",
   "metadata": {},
   "source": [
    "## Method & Results\n",
    "\n",
    "In this section, we provide a detailed depiction of the methodologies employed in our analysis and the key results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad104da7",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "The dataset utilized for this project originates from Kaggle, available at https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data. The available information includes details about the properties on Airbnb, the corresponding geographical information, price, and the room type. It comprises 16 columns and a substantial volume of data, totaling 48895 rows. Given the large dataset size, 70% of the dataset is used for training the models while the remaining 30% is used for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8539a02c-8575-43b6-b519-024d7db67447",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be02b47-3404-48fa-984e-b06ec26e2e57",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis \n",
    "\n",
    "The following exploratory data analysis techniques were used to gain insight into the data and drive the next steps in model development. \n",
    "\n",
    " - **Summary Statistics:** Key statistics for numerical columns, like the mean, minimum, maximum, and standard deviation, were used to gain an overview of the central tendencies of the data.  Observing the number of unique values within a column also helped identify the features which are unique identifiers such as `id` which do not help the model in learning any new patterns.\n",
    "\n",
    "- **Visualizations:** Observation of the distributions of numeric and categorical columns was done to identify skewness in numerical features, and detect imbalance in the categorical groups. Additionally, the pairwise correlations of numerical features were calculated to identify strong relationships between the features which are to be dealt with accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c032b39",
   "metadata": {},
   "source": [
    "#### Distribution of Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29825f83",
   "metadata": {},
   "source": [
    "Observing two meaningful categorical columns, `room_type` and `neighbourhood_group`, we see that the listings in the dataset are primarily 'Entire Home/Apt' or 'Private Room' types, and are located in Brooklyn or Manhattan. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26432262",
   "metadata": {},
   "source": [
    "```{figure} ../output/img/categorical_barcharts.png \n",
    "---\n",
    "width: 1000px\n",
    "name: categorical_barcharts\n",
    "---\n",
    "Barcharts for `room_type` and `neighboorhood group` features. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc02d2",
   "metadata": {},
   "source": [
    "#### Distribution of Numeric Features\n",
    "\n",
    "The following graphs provide the distributions for the meaningful numeric features in dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c948e",
   "metadata": {},
   "source": [
    "```{figure} ../output/img/numerical_density_plots.png \n",
    "---\n",
    "width: 1000px\n",
    "name: numerical_density_plots\n",
    "---\n",
    "Density plots portraying the distribution of numerical features in the dataset. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e8436",
   "metadata": {},
   "source": [
    "Many of the distributions, like `reviews_per_month` and `number_of_reviews`, are right-skewed and contain extreme outliers. Notably, `availability_365` has a significant number of values with 0. This indicates that several listings were not available to book for any day of the year, at least at the time of data collection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ece03",
   "metadata": {},
   "source": [
    "#### Distribution of the Target Variable: Price "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35315816",
   "metadata": {},
   "source": [
    "In this section we look in depth at the distribution of the target variable, price. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b3a256",
   "metadata": {},
   "source": [
    "```{figure} ../output/img/target_dist_plots.png \n",
    "---\n",
    "width: 1000px\n",
    "name: target_dist_plots\n",
    "---\n",
    "The distribution of the target variable. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b9de0d",
   "metadata": {},
   "source": [
    "The distribution of price is right-skewed with extreme outliers, which can pose challenges for model prediction. Also, values with a price equal to zero may indicate an error, as a free listing price is highly unexpected. To gain more insight, we explored the price distribution, based on the features: room type, neighborhood group, and number of reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc5793d",
   "metadata": {},
   "source": [
    "```{figure} ../output/img/target_dist_grouped_cat.png\n",
    "---\n",
    "width: 1000px\n",
    "name: target_dist_plots_cat\n",
    "---\n",
    "The distribution of the target variable by the categories in room type and neighbourhood. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b14be",
   "metadata": {},
   "source": [
    "All categories display right-skewed distributions with outliers and varying degrees of spread. Notably, the 'Entire home/apt' room type has the highest median price per night of \\$160, and the 'Shared Room' type has the lowest at $45 per night. Furthermore, listings in Manhattan boast the highest median price at \\$150 per night, whereas the Bronx has the lowest at \\$65 per night. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf9a40",
   "metadata": {},
   "source": [
    "```{figure} ../output/img/target_dist_grouped_num.png\n",
    "---\n",
    "width: 1000px\n",
    "name: target_dist_plots_num \n",
    "---\n",
    "The distribution of the target variable based on the number of reviews. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454482d1",
   "metadata": {},
   "source": [
    "The scatter plot reveals a significant clustering of listings within the range of 0 to 50 reviews and 0 to 500 dollars per night. Additionally, those outlier listings with high price per night have less reviews. Likewise, there exist many listings with low price per night but a high number of reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a2c11",
   "metadata": {},
   "source": [
    "#### Correlation of Numeric Variables\n",
    "\n",
    "The Pearson and Spearman correlations are calculated to gain insight into possible relationships between the numeric variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34700f71",
   "metadata": {},
   "source": [
    "```{figure} ../output/img/correlation_plot.png\n",
    "---\n",
    "width: 1000px\n",
    "name: correlation_plot\n",
    "---\n",
    "The Pearson and Spearman correlations of numeric variables. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b2bc5",
   "metadata": {},
   "source": [
    "As expected we see a positive correlation for the number of reviews and reviews per month. The correlation magnitudes are not extreme for the other pairings. Interestingly, price and longitude have a -0.15 Pearson correlation and a moderate Spearman correlation of -0.44. This suggests that while there isn't a strong linear relationship, there is a moderate monotonic trend, indicating that price generally decreases as longitude increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5ea4e",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "The following data-cleaning steps were implemented to prepare the dataset for model development.\n",
    "\n",
    "- **Price equal to zero:** Rows with a price equal to zero were removed, since these rows may have resulted from an error and make it more challenging for predictive models to grasp patterns in the data. \n",
    "- **NaN in reviews_per_month:** For rows with NaN in `reviews_per_month`, `number_of_reviews` is zero, indicating no reviews. Thus, we replace NaN with zero.\n",
    "- **NaN in last_review:** For rows with NaN in `last_reviews`, `number_of_reviews` is zero, indicating no reviews. Thus, we replaced NaN with the date 1900-01-01 to distinguish between listings that have never received a review and those that have.\n",
    "- **last_review type**: Converted `last_review` to a datetime object for easier processing in later steps.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d79f48",
   "metadata": {},
   "source": [
    "### Feature Engineering \n",
    "\n",
    "We engineered various features to enhance our models' predictive power. These engineered features are outlined below.  \n",
    "\n",
    "- `estimated_listed_months`: This feature aims to estimate how long a listing has been listed based on the number of reviews it has received and the average number of reviews it gets per month, using the formula: $\\text{estimated_listed_months} = \\frac{\\text{number_of_reviews}}{\\text{reviews_per_month}}$\n",
    "- `availability_ratio`: This feature provides the proportion of the year that a listing is available for booking, using the formula: $\\text{availability_ratio} = \\frac{\\text{availability_365}}{365}$\n",
    "- `days_since_last_review`: This feature provides the number of days since the last review, utilizing information from `last_review`.  \n",
    "- `distance_from_city_center`: This feature provides the number of kilometers the listing is from the NYC center, using the haversine formula and information from the `latitude` and `longitude` features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6358ce-7bdf-4a21-8fae-3177ede4edbd",
   "metadata": {},
   "source": [
    "### Preprocessing and Transformations\n",
    "\n",
    "The following preprocessing and transformation steps, as justified below, were applied to prepare the dataset for model training. \n",
    "\n",
    "**Dropped Features:**\n",
    "- `id`, `name`, `host_id`, `host_name`: These features all have a high number of unique values, with `id` being a unique identifier. \n",
    "- `last_review`: This feature was dropped since we used `days_since_last_review` instead.   \n",
    "- `neighbourhood`: Given the other location-based features in the dataset, along with experimentation results, dropping `neighbourhood` permitted the best results.\n",
    "- `availability_365`: This feature was dropped for redundancy since we've opted to use `availability_ratio` which offers a normalized and more interpretable measure of availability. \n",
    "- `number_of_reviews`: This feature was dropped for redundancy since we used `reviews_per_month` instead. \n",
    "\n",
    "**Categorical Features:**\n",
    "- `neighbourhood_group` and `room_type`: Both of these features are nominal values so one-hot-enconder with `handle_unknown=True` was applied.\n",
    "\n",
    "**Numeric Features:**\n",
    "- `latitude`, `longitude`, `minimum_nights`, `calculated_host_listings_count`, `reviews_per_month`, `estimated_listed_months`, `availability_ratio`, `days_since_last_review`, `distance_from_city_center`: Standard scalar was used on these numeric features to put them on the same scale so that no feature disproportionately influences the models due to its scale.  \n",
    "\n",
    "**Skewed Target Variable:** \n",
    "- `price`: A log transformation on `price` was applied to reduce the skewness and make the distribution more normal, which can enhance the performance of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee294a2a",
   "metadata": {},
   "source": [
    "#### Updated Correlations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81db823",
   "metadata": {},
   "source": [
    "After feature engineering and preprocessing we observe the updated Pearson and Spearman correlations, below.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ac374",
   "metadata": {},
   "source": [
    "```{figure} ../output/img/correlation_updated_plot.png\n",
    "---\n",
    "width: 1000px\n",
    "name: correlation_updated_plot\n",
    "---\n",
    "The Pearson and Spearman correlations after feature engineering and preprocessing.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f99445",
   "metadata": {},
   "source": [
    "For the engineered features we created, there are moderate correlations for `distance_from_city_center` and `longitude`, along with `days_since_last_review` and `estimated_listed_months`. Notably, we see a strong negative Spearman correlation for `reviews_per_month` and `days_since_last_review`, suggesting that as the number of reviews per month increases, the time since the last review decreases. While these two features have a strong Spearman correlation, the Pearson correlation is only -0.34. We've opted to keep both features at this point, as they both may provide valuable information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403230f",
   "metadata": {},
   "source": [
    "### Model Development\n",
    "\n",
    "The next step in our analysis was to build the model pipelines and evaluate the models. The scoring metric we used is $R^2$ since we compared several regression models. Additional metrics, described later, were used for feature importance and further analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef7bdf7-b2aa-4fda-b1ae-a3a6a924092e",
   "metadata": {},
   "source": [
    "#### Baseline Model \n",
    "\n",
    "We used the Dummy Regressor from the scikit-learn package as our baseline model. It has poor performance with a train and test (validation) $R^2$ score of 0.000 and 0.000, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb118985",
   "metadata": {},
   "source": [
    "#### Linear model\n",
    "\n",
    "Ridge from scikit-learn was our first linear model which also had poor performance. The $R^2$ scores for the training and test (validation) sets were 0.518 and 0.517, respectively. While these results are an improvement over the baseline model and don't show signs of overfitting, there is still room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a25971-6e1a-4fa6-b812-8b5429047850",
   "metadata": {},
   "source": [
    "#### Ensemble Models \n",
    "\n",
    "We experimented with three ensemble models: The Random Forest Regressor, XGBoost Regressor, and LightGBM Regressor. Overall, the ensemble models showed better results compared to the linear and baseline models. A summary table with the results is provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "600bc03d",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dummy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ridge</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Random Forest</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LGBM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Dummy       Ridge        Random Forest        XGBoost         \\\n",
       "             mean  std   mean    std          mean    std    mean    std   \n",
       "test_score   -0.0  0.0  0.517  0.019         0.592  0.018   0.578  0.018   \n",
       "train_score   0.0  0.0  0.518  0.002         0.688  0.002   0.588  0.003   \n",
       "\n",
       "              LGBM         \n",
       "              mean    std  \n",
       "test_score   0.605  0.018  \n",
       "train_score  0.656  0.002  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921c19f",
   "metadata": {},
   "source": [
    "As observed, the top two performing models are the LightGBM Regressor, which achieved a training score of 0.658 and a test score of 0.605, and the Random Forest Regressor, with a training score of 0.695 and a test score of 0.591. The gaps in the training and test scores for these models are small, indicating minimal overfitting. XGBoost follows as the third highest-performing model, with a training score of 0.596 and a test score of 0.583. All these models significantly outperform both the Ridge Regressor and the Dummy Regressor (baseline model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceacb4d-fbb8-4beb-a45e-bb737198c44e",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization\n",
    "\n",
    "Hyperparameter optimization was then performed to fine-tune the ensemble models, aimed at enhancing the predictive accuracy. Using RandomizedSearchCV with various parameter spaces for each model, we were able to slightly improve the training and test scores for all three models. However, the LGBM fine-tuned model had the most promising results with the highest test score,{glue:text}`lgbm_tuned_test`,  and a relatively small discrepancy from the train score, {glue:text}`lgbm_tuned_train`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdcdceb-7bbb-4b80-af49-0ab1cfca8a35",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "We decided to move forward with the LGBM Regressor and perform Recursive Feature Elimination with Cross-Validation (RFECV) and L1 regularization to optimize feature selection and improve model performance by identifying important features while reducing dimensionality. This model was at par with the hyperparameter-optimized LGMB model but showed more consistent train and test scores, as observed in the summary table of results below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9208f05",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dummy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ridge</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Random Forest</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LGBM</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RF_Tuned</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGB_Tuned</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LGBM_Tuned</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFECV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Dummy       Ridge        Random Forest        XGBoost         \\\n",
       "             mean  std   mean    std          mean    std    mean    std   \n",
       "test_score   -0.0  0.0  0.517  0.019         0.592  0.018   0.578  0.018   \n",
       "train_score   0.0  0.0  0.518  0.002         0.688  0.002   0.588  0.003   \n",
       "\n",
       "              LGBM        RF_Tuned        XGB_Tuned        LGBM_Tuned         \\\n",
       "              mean    std     mean    std      mean    std       mean    std   \n",
       "test_score   0.605  0.018    0.594  0.006     0.611  0.014      0.610  0.014   \n",
       "train_score  0.656  0.002    0.794  0.000     0.708  0.002      0.686  0.003   \n",
       "\n",
       "             RFECV         \n",
       "              mean    std  \n",
       "test_score   0.607  0.019  \n",
       "train_score  0.652  0.002  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765f4bc3-a5a5-4d95-bc90-876499811fc4",
   "metadata": {},
   "source": [
    "### Feature Importances\n",
    "\n",
    "Given that the top two test scores are 0.610 for the LGBM Regressor and 0.607 for the RFECV model, we proceeded with the RFECV model due to its smaller discrepancy between training and test scores. Now, we dive further into the feature importances for more insight. \n",
    "\n",
    "The RFECV selected features, with their corresponding importance value are listed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f58273",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_10b56\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_10b56_level0_col0\" class=\"col_heading level0 col0\" >Feature</th>\n",
       "      <th id=\"T_10b56_level0_col1\" class=\"col_heading level0 col1\" >Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row0_col0\" class=\"data row0 col0\" >longitude</td>\n",
       "      <td id=\"T_10b56_row0_col1\" class=\"data row0 col1\" >881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row1_col0\" class=\"data row1 col0\" >availability_ratio</td>\n",
       "      <td id=\"T_10b56_row1_col1\" class=\"data row1 col1\" >749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row2_col0\" class=\"data row2 col0\" >distance_from_city_center</td>\n",
       "      <td id=\"T_10b56_row2_col1\" class=\"data row2 col1\" >674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row3_col0\" class=\"data row3 col0\" >latitude</td>\n",
       "      <td id=\"T_10b56_row3_col1\" class=\"data row3 col1\" >645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row4_col0\" class=\"data row4 col0\" >minimum_nights</td>\n",
       "      <td id=\"T_10b56_row4_col1\" class=\"data row4 col1\" >598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row5_col0\" class=\"data row5 col0\" >calculated_host_listings_count</td>\n",
       "      <td id=\"T_10b56_row5_col1\" class=\"data row5 col1\" >517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row6_col0\" class=\"data row6 col0\" >estimated_listed_months</td>\n",
       "      <td id=\"T_10b56_row6_col1\" class=\"data row6 col1\" >473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row7_col0\" class=\"data row7 col0\" >days_since_last_review</td>\n",
       "      <td id=\"T_10b56_row7_col1\" class=\"data row7 col1\" >472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row8_col0\" class=\"data row8 col0\" >reviews_per_month</td>\n",
       "      <td id=\"T_10b56_row8_col1\" class=\"data row8 col1\" >437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row9_col0\" class=\"data row9 col0\" >room_type_Shared room</td>\n",
       "      <td id=\"T_10b56_row9_col1\" class=\"data row9 col1\" >99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row10_col0\" class=\"data row10 col0\" >room_type_Entire home/apt</td>\n",
       "      <td id=\"T_10b56_row10_col1\" class=\"data row10 col1\" >74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row11_col0\" class=\"data row11 col0\" >neighbourhood_group_Manhattan</td>\n",
       "      <td id=\"T_10b56_row11_col1\" class=\"data row11 col1\" >26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row12_col0\" class=\"data row12 col0\" >neighbourhood_group_Bronx</td>\n",
       "      <td id=\"T_10b56_row12_col1\" class=\"data row12 col1\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row13_col0\" class=\"data row13 col0\" >neighbourhood_group_Brooklyn</td>\n",
       "      <td id=\"T_10b56_row13_col1\" class=\"data row13 col1\" >19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_10b56_row14_col0\" class=\"data row14 col0\" >neighbourhood_group_Queens</td>\n",
       "      <td id=\"T_10b56_row14_col1\" class=\"data row14 col1\" >16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22713487590>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f110ce34",
   "metadata": {},
   "source": [
    "Noticeably, features related to location like `longitude`, `distance_from_city_center`, and `latitude` have high importance, along with features related to availability and booking, like `availability_ratio` and `minimum_nights`. Whereas, specific neighbourhood groups are showing less importance in comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6505d09c",
   "metadata": {},
   "source": [
    "### Test Set Scoring <a name=\"1\"></a>\n",
    "\n",
    "We use R² for consistency with our previous analysis. We also calculated the Mean Absolute Error (MAE), as it handles outliers well, and provides additional interpretability and robustness in evaluating the RFECV model.\n",
    "\n",
    "The final $R^2$ test score is {glue:text}`final_r2`. While the test MAE is {glue:text}`rfecv_mae`. Additionally, the MAE scores of the Linear and Dummy models are displayed below, for comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfc6355b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3c6b1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_3c6b1_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_3c6b1_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_3c6b1_row0_col0\" class=\"data row0 col0\" >RFECV</td>\n",
       "      <td id=\"T_3c6b1_row0_col1\" class=\"data row0 col1\" >58.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3c6b1_row1_col0\" class=\"data row1 col0\" >Linear</td>\n",
       "      <td id=\"T_3c6b1_row1_col1\" class=\"data row1 col1\" >64.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3c6b1_row2_col0\" class=\"data row2 col0\" >Dummy</td>\n",
       "      <td id=\"T_3c6b1_row2_col1\" class=\"data row2 col1\" >86.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22715097ad0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_comparison_style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba9ced",
   "metadata": {},
   "source": [
    "The $R^2$ score of 0.61 tells us that the RFECV model explains 61% of the variability in the listing prices. While this is a moderate level of performance, there is 39% of the variability that is not explained. Additionally, the MAE of 58.77. tells us that the RFECV model's predictions are \\$58.77 away from the actual listing prices on average. This is an advancement from the Dummy and Linear model, but there is still room for improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea52f45",
   "metadata": {},
   "source": [
    "### SHAP Values <a name=\"1\"></a>\n",
    "\n",
    "We delved deeper into the analysis by looking at SHAP values to understand the influence of specific features on individual predictions. It is important to note, that due to the log transformation on our target value, the SHAP values become slightly less interpretable since the units are *log of dollars*. However, the SHAP plots serve to illustrate the relative impact of each feature on the model's predictions, providing valuable insights into feature importance and interactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f9bc2a",
   "metadata": {},
   "source": [
    "#### SHAP Summary Plot\n",
    "\n",
    "First, we consider the SHAP Summary plot which provides an overview of all SHAP values for all data points in the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc27c95",
   "metadata": {},
   "source": [
    "```{figure} ../output/img/shap_summary.png\n",
    "---\n",
    "width: 1000px\n",
    "name: shap_summary\n",
    "---\n",
    "The SHAP summary plot for the test set. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d47510a",
   "metadata": {},
   "source": [
    "This plot provides evidence that characteristics like the type of room, the distance from the city center, and the availability of the listing play a clear role in predicting the listing price. For instance, the red cluster of points for `room_type_Entire home/apt` indicates that listings where users get to rent out the entire place contribute significantly to increasing the model's predicted listing price. Whereas, listings that don't rent out the entire place (indicated by the blue clusters for `room_type_Entire home/apt`) contribute by decreasing the predicted price. This interpretation is somewhat consistent with the conclusion we can gain from the clusters for `room_type_Shared room`. Likewise, the extended blue cluster for `distance_from_city_center` indicates a closer distance to the city center will contribute to higher predicted prices, and the red cluster indicates a larger distance from the city center will contribute to lower predicted prices. The remaining features can be analyzed similarly, but we see some features having less influence like `neighbourhood_group_Brooklyn`, or less clear-cut divisions, like `calculated_host_listings_count`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f1a94a",
   "metadata": {},
   "source": [
    "#### SHAP Values for Individual Predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a104f9",
   "metadata": {},
   "source": [
    "Next, we focus on two specific predictions (a high-value and low-value) from the test set to gain a deeper understanding of the model's predictions and the driving factors behind them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea275e",
   "metadata": {},
   "source": [
    "The plot below gives insight into how different features impacted the model's prediction, resulting in a predicted value of $f(x) = 3.919$ (or $\\$50.35$), which is well below the average (or expected) value of $E[f(x)] = 4.725$ (or $\\$113.27$). The  `room_type_entire home/apt` had the most negative impact, reducing the prediction by -0.47. Whereas, the `availability_ratio` value contributes positively by increasing the prediction by 0.3. The other features follow similarly, either increasing (those in red) or decreasing (those in blue) the prediction value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40bcd8",
   "metadata": {},
   "source": [
    "```{figure} ../output/img/shap_less_plot.png\n",
    "---\n",
    "width: 1000px\n",
    "name: shap_less_plot\n",
    "---\n",
    "The SHAP plot for a small predicted value. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b934c",
   "metadata": {},
   "source": [
    "In the plot below, we have an example data point with a much higher prediction of $f(x) = 5.389$ (or $\\$218.98$). We see that the `room_type_entire home/apt` value has the largest positive impact, increasing the prediction by 0.41. Likewise, `distance_from_city_center` has the second largest impact, increasing the prediction by 0.21. As before, the other features had a less significant impact, either increasing or decreasing the predicted value.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab5e3f",
   "metadata": {},
   "source": [
    "```{figure} ../output/img/shap_gr_plot.png\n",
    "---\n",
    "width: 1000px\n",
    "name: shap_gr_plot\n",
    "---\n",
    "The SHAP plot for a large predicted value.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9263e5-0f00-4170-a7d1-aa47e0bf3bd6",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260a91aa-9667-4944-93f4-80fa139c7129",
   "metadata": {},
   "source": [
    "To identify the optimal model for predicting Airbnb listing prices, this analysis explored a variety of models, beginning with a baseline Dummy Regressor and gradually increasing in complexity. Early insights from our EDA gave us a foundational understanding of the feature distributions, serving as a guide for feature engineering and model development. Engineered features, like distance from the city center, enhanced the models' abilities to capture patterns in the data&mdash;as indicated by a high feature importance value and reflected in the SHAP summary plot. After performing hyperparameter optimization and recursive feature selection we arrived at the best-performing RFECV model. \n",
    "\n",
    "The RFECV model utilizes recursive feature elimination to optimize feature selection and reduce dimensionality while incorporating cross-validation. From the hyperparameter optimization results, we decided to implement RFECV with the top-performing LGBM Regressor, along with L1 regularization to prevent overfitting. The RFECV model achieved an $R^2$ test score of 0.61. This score reflects a moderate to good fit and is relatively consistent with the 0.65 train score. However, a score of 0.61 reveals that 39% of the variability in listing price can not be explained by the RFECV model, leaving room for improvement. \n",
    "\n",
    "Additionally, the RFECV model achieved an MAE of \\$58.75. While this is an improvement from the dummy and linear models, it too signifies a sub-optimal level of performance, when we consider the median listing price of \\$106 in the test set. Despite this, insight from the feature importances and SHAP values provides quantifiable measures for the impact the different features have on the model's predictions. Overall, room type, location features (like longitude and distance from the city center), and minimum nights, appear valuable in predicting the the listing prices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e2284f",
   "metadata": {},
   "source": [
    "### Limitations and Future-work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d70be",
   "metadata": {},
   "source": [
    "Despite the thorough methods implemented in this analysis, the sub-optimal model performance can be attributed to a few factors. Firstly, 36% of the listings had listed 0 available days for booking. With no other information on why these listings were unavailable or how long they have been unavailable, the model can not capture external factors that could be at play for these listings. For instance, if a listing has been unavailable for a long time its listing price could be outdated. This uncertainty on such a large portion of the data causes lots of noise, making it challenging for the models to understand patterns in the data. More information on these listings would allow for appropriate handling of these data points. \n",
    "\n",
    "Furthermore, the outliers in the target variable (price) pose challenges to model performance. 6% of listing prices were greater than 1.5 times the interquartile range. These outliers can skew the model performance by distorting the patterns in the data. While tree-based models are generally less sensitive to outliers, the large amount of outliers can still negatively impact model performance. Comparing model performance after removing outliers or exploring additional ensemble methods, like stacking, could improve results. Lastly, it's notable that a very small portion of the listings had a price listed as 0&mdash;indicative of errors in the data. While this portion is small it raises concern with data quality. \n",
    "\n",
    "In conclusion, while this analysis remains robust in its efforts to predict Airbnb listing prices, the presence of data limitations and outliers requires further refinement. Future work could focus on exploring advanced ensemble models, using updated data, and ensuring data quality.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2167c5-1c54-4990-9541-1a5f7a08a757",
   "metadata": {},
   "source": [
    "\n",
    "## References\n",
    "\n",
    "Airbnb. (2024). *About us*. URL: https://news.airbnb.com/about-us/\n",
    "\n",
    "### Core Libraries \n",
    "\n",
    "Hunter, J. D. (2007). *Matplotlib: A 2D Graphics Environment.* Computing in Science & Engineering, 9(3), 90-95. URL: https://matplotlib.org/\n",
    "\n",
    "Lundberg, S. M., & Lee, S. I. (2017). *A Unified Approach to Interpreting Model Predictions.* In Advances in Neural Information Processing Systems (NIPS 2017). URL: https://shap.readthedocs.io/en/latest/\n",
    "\n",
    "McKinney, W. (2010). *Data Analysis with Python and Pandas.* URL: https://pandas.pydata.org/\n",
    "\n",
    "Pedregosa, F., et al. (2011). *Scikit-learn: Machine Learning in Python.* Journal of Machine Learning Research, 12, 2825-2830. URL: https://scikit-learn.org/\n",
    "\n",
    "Van der Walt, S., Colbert, S. C., & Varoquaux, G. (2011). *The NumPy Array: A Structure for Efficient Numerical Computation.* Computing in Science & Engineering, 13(2), 22-30. URL: https://numpy.org/\n",
    "\n",
    "Vega, J., & Altair Development Team. (2017). *Altair: A Declarative Statistical Visualization Library for Python.* URL: https://altair-viz.github.io/\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "573",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
